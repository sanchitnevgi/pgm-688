{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import plotly.express as px\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAT_LEN = 10\n",
    "LABELS = list('etainoshrd')\n",
    "\n",
    "char_to_label = { char: idx for idx, char in enumerate(LABELS) }\n",
    "label_to_char = { idx: char for char, idx in char_to_label.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_array(file):\n",
    "    return np.loadtxt(file)\n",
    "\n",
    "def get_features(num, split='train'):\n",
    "    '''\n",
    "    Return train/test data as ndarray\n",
    "    Shape: (seq_len, feature_dim)\n",
    "    '''\n",
    "    return read_array(f'./data/{split}_img{num}.txt')\n",
    "\n",
    "def normalize(ndarray, axis=0):\n",
    "    return ndarray / ndarray.sum(axis=axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature params shape (10, 321)\n",
      "Transition params shape (10, 10)\n"
     ]
    }
   ],
   "source": [
    "feature_params = read_array('./model/feature-params.txt')\n",
    "print('Feature params shape', feature_params.shape)\n",
    "\n",
    "transition_params = read_array('./model/transition-params.txt')\n",
    "print('Transition params shape', transition_params.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theodore [1, 7, 0, 5, 9, 5, 8, 0]\n"
     ]
    }
   ],
   "source": [
    "def get_word(labels):\n",
    "    return ''.join([label_to_char[label] for label in labels])\n",
    "\n",
    "def get_labels(split='train'):\n",
    "    labels = []\n",
    "    with open(f'./data/{split}_words.txt') as file:\n",
    "        for word in file:\n",
    "            labels.append([char_to_label[char] for char in word.rstrip('\\n')])\n",
    "    return labels\n",
    "\n",
    "train_labels = get_labels(split='train')\n",
    "test_labels = get_labels(split='test')\n",
    "\n",
    "print('theodore', train_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Exhaustive Inference\n",
    "\n",
    "The CRF also contains one transition parameter $W_{cc′}$ for each pair of character labels c and c .\n",
    "The transition parameters encode the \"compatibility\" between adjacent character labels in the word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_feat_potential(features, params):\n",
    "    '''\n",
    "        features: ndarray of shape (length, dims). dims = 231\n",
    "        params: ndarray of shape (categories, dims) categories = 10\n",
    "        \n",
    "        return: potentials of shape (seq length, categories)\n",
    "    '''\n",
    "    return np.exp(features @ params.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_tran_potential(params):\n",
    "    '''\n",
    "        Calculates the transition potentials.\n",
    "        params: ndarray of shape (categories, categories)\n",
    "        \n",
    "        Return: ndarray of shape (cat, cat) \n",
    "        potential[y_1,y_2] will give the potential from label y_1 to y_2\n",
    "    '''\n",
    "    return np.exp(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_potens(test_case=1):\n",
    "    features = get_features(test_case, split='test')\n",
    "    \n",
    "    feature_potens = calc_feat_potential(features, feature_params)\n",
    "    trans_potens = calc_tran_potential(transition_params)\n",
    "    \n",
    "    return feature_potens, trans_potens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Feature potentials of $test_0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -7.644354,  18.46838 ,  -6.328565,  10.422494,  -4.967162,\n",
       "         -1.934011,  -0.945172,  -5.657108,   5.395295,  -6.809825],\n",
       "       [ -4.074483,   5.744835,   1.176369,  -1.793123,  -1.212227,\n",
       "         -1.78488 ,  -8.299875,   3.095185,   6.806588,   0.341613],\n",
       "       [-10.208138,   0.897342,  17.191008, -12.017674,   5.57936 ,\n",
       "         -0.594043, -21.426366,   9.148904,   9.482416,   1.947176],\n",
       "       [  6.464858,  24.531253, -13.342905,   5.871221, -10.95484 ,\n",
       "        -11.496499,  -5.494649,  -7.195623,   8.045658,   3.571496]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_1 = get_features(1, split='test')\n",
    "\n",
    "# Calculate potentials in log space\n",
    "log_potentials = np.log(calc_feat_potential(test_1, feature_params))\n",
    "log_potentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Energy Calculation\n",
    "\n",
    "Energy is a function which measures the “goodness” (or badness) of each possible configuration of the random variables (the lower the engergy, the better the configuration).\n",
    "Define energy as the negative logarithm of (possibly unnormalized) probability.\n",
    "\n",
    "For the first three test words, compute the value of the negative energy of the true label sequence after conditioning on the corresponding observed image sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_energy(feat_potens, trans_params, true_labels):\n",
    "    '''\n",
    "        Calculate the **negative** energy of a distribution. Energy is defined as negative logarithm of probability\n",
    "        \n",
    "        feat_poten: ndarray of shape (seq length, categories): Feature potentials\n",
    "        trans_params: ndarray of shape (categories, categories): Transition parameters\n",
    "        \n",
    "        returns: ndarray of shape (categories)\n",
    "    '''\n",
    "    # Calculate the feature potentials of true labels\n",
    "    feat_comp = np.log(feat_potens[range(len(true_labels)), true_labels]).sum()\n",
    "    \n",
    "    # Calculate the transition potentials of true labels\n",
    "    trans_comp = trans_params[true_labels[:-1], true_labels[1:]].sum()\n",
    "    \n",
    "    energy = feat_comp + trans_comp\n",
    "    \n",
    "    return energy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test word 1: 63.979336\n",
      "Test word 2: 89.61093\n",
      "Test word 3: 96.940634\n"
     ]
    }
   ],
   "source": [
    "# Energy for first 3 test words\n",
    "for i in range(3):\n",
    "    features = get_features(i + 1, split='test')\n",
    "    feature_potentials = calc_feat_potential(features, feature_params)\n",
    "    energy = calc_energy(feature_potentials, transition_params, test_labels[i])\n",
    "    print(f'Test word {i + 1}:', energy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3, 1.4:  Log Partition function, Most-likely\n",
    "\n",
    "Calculate $\\log Z$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_potential_for_seq(sequence, feat_potens, trans_potens):\n",
    "    potential = 1\n",
    "    # Feature poten\n",
    "    for seq_i, label in enumerate(sequence):\n",
    "        potential *= feat_potens[seq_i, label]\n",
    "\n",
    "    # Transition poten\n",
    "    for seq_i, label in enumerate(sequence[:-1]):\n",
    "        next_label = sequence[seq_i + 1]\n",
    "        potential *= trans_potens[label, next_label]\n",
    "\n",
    "    return potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_log_partition(features):\n",
    "    '''\n",
    "     Get a (categories,) array and sum it up. Since x is observed\n",
    "    '''\n",
    "    \n",
    "    feat_potens = calc_feat_potential(features, feature_params)\n",
    "    trans_potens = calc_tran_potential(transition_params)\n",
    "    \n",
    "    cat_len = 10\n",
    "    seq_len, dim_len = features.shape\n",
    "    \n",
    "    possiblities = [range(cat_len)] * seq_len\n",
    "\n",
    "    log_partition = 0\n",
    "    most_likely = (None, float('-inf'))\n",
    "    \n",
    "    # Go over all possible sequences\n",
    "    for sequence in product(*possiblities):\n",
    "        potential = calc_potential_for_seq(sequence, feat_potens, trans_potens)\n",
    "\n",
    "        if potential > most_likely[1]:\n",
    "            most_likely = (sequence, potential)\n",
    "\n",
    "        log_partition += potential\n",
    "        \n",
    "    print('Most Likely: ', get_word(most_likely[0]), 'Prob: ', most_likely[1] / log_partition)\n",
    "    \n",
    "    return np.log(log_partition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Likely:  trat Prob:  0.7958187630401371\n",
      "Test 1: 67.60187580368476\n",
      "Most Likely:  hire Prob:  0.9965204924093368\n",
      "Test 2: 89.61441557515604\n",
      "Most Likely:  riser Prob:  0.9370071414912935\n",
      "Test 3: 103.52757237511717\n"
     ]
    }
   ],
   "source": [
    "# Log partition for first 3 test words\n",
    "for i in range(3):\n",
    "    features = get_features(i+1, split='test')\n",
    "    log_partition = calc_log_partition(features)\n",
    "    print(f'Test {i+1}:', log_partition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Marginal Probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.22268182e-12, 1.26583711e-05, 1.13213821e-12, 8.86828033e-09],\n",
       "       [9.99524645e-01, 1.72473165e-01, 2.29451201e-08, 9.99999919e-01],\n",
       "       [2.62616683e-11, 2.73136691e-03, 9.99458877e-01, 2.13566003e-17],\n",
       "       [4.72721273e-04, 1.75283394e-04, 1.61185516e-13, 7.40542921e-09],\n",
       "       [7.15554575e-11, 2.00735648e-04, 3.69756698e-06, 3.29004119e-16],\n",
       "       [2.11384828e-09, 1.40047474e-04, 1.76109354e-08, 1.44100307e-16],\n",
       "       [3.29598967e-09, 1.06460709e-07, 5.17214285e-18, 5.37109230e-14],\n",
       "       [4.34926966e-11, 2.67352876e-02, 2.83525328e-04, 1.31780714e-14],\n",
       "       [2.62808981e-06, 7.96595064e-01, 2.53764930e-04, 6.39397930e-08],\n",
       "       [1.06936989e-11, 9.36285224e-04, 9.46377346e-08, 6.37362801e-10]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_marginal():\n",
    "    features = get_features(1, split='test')\n",
    "    feat_potens = calc_feat_potential(features, feature_params)\n",
    "    trans_potens = calc_tran_potential(transition_params)\n",
    "\n",
    "    cat_len = 10\n",
    "    seq_len, dim_len = features.shape\n",
    "    \n",
    "    possiblities = [range(cat_len)] * seq_len\n",
    "    probs = np.zeros((seq_len, cat_len))\n",
    "    \n",
    "    for sequence in product(*possiblities):\n",
    "        potential = calc_potential_for_seq(sequence, feat_potens, trans_potens)\n",
    "        \n",
    "        for seq_i, label in enumerate(sequence):\n",
    "            probs[seq_i, label] += potential\n",
    "\n",
    "    probs = probs / probs.sum(axis=1).reshape(-1, 1)\n",
    "\n",
    "    return probs\n",
    "\n",
    "probs = get_marginal()\n",
    "probs.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Sum-Message Passing\n",
    "\n",
    "In this question, you will implement the sum-product inference algorithm for the CRF model. The code packages provides a pre-trained model for the OCR task including the feature parameters (feature-params.txt) and the label-label transition parameters (transition-params.txt). Use these parameters to answer the following questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Log-space messages\n",
    "\n",
    "For the first test word only, condition on the observed image sequence to obtain a chain-structured Markov network. Compute the log-space messages \n",
    "\n",
    "$m_{1 \\rightarrow 2}(Y_2)$, \n",
    "\n",
    "$m_{3 \\rightarrow 1}(Y_1)$, \n",
    "\n",
    "$m_{2 \\rightarrow 3}(Y_3)$, \n",
    "\n",
    "$m_{3 \\rightarrow 2}(Y_2)$\n",
    "\n",
    "Report the value of each message in a table. 10 values per message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_messages(feature_potens, trans_potens, forward=True):\n",
    "    '''\n",
    "        Calculate the **log-space** messages that are passed from i -> j\n",
    "        \n",
    "        feature_potens: ndarray (seq_len, cat_len)\n",
    "        trans_potens: ndarray (cat_len, cat_len)\n",
    "        \n",
    "        forward: Compute the messages forward 1 -> 2, or backward 2 -> 1\n",
    "        \n",
    "        Returns: msg: Dict[(from, to)] -> ndarray (categories,)\n",
    "    '''\n",
    "    msg = dict()\n",
    "\n",
    "    seq_len, cat_len = feature_potens.shape\n",
    "\n",
    "    if forward:\n",
    "        msg[0, 1] = np.ones(cat_len)\n",
    "\n",
    "        for seq_i in range(1, seq_len):\n",
    "            msg[seq_i, seq_i + 1] = np.zeros(cat_len)\n",
    "\n",
    "            for cat_i in range(cat_len):\n",
    "                for cat_j in range(cat_len):\n",
    "                    msg[seq_i, seq_i + 1][cat_i] += (feature_potens[seq_i - 1, cat_j] \n",
    "                                       * trans_potens[cat_i, cat_j] \n",
    "                                       * msg[seq_i - 1, seq_i][cat_j])\n",
    "    else:\n",
    "        msg[seq_len + 1, seq_len] = np.ones(cat_len)\n",
    "\n",
    "        for seq_i in range(seq_len, 1, -1):\n",
    "            msg[seq_i, seq_i - 1] = np.zeros(cat_len)\n",
    "\n",
    "            for cat_i in range(cat_len):\n",
    "                for cat_j in range(cat_len):\n",
    "                    msg[seq_i, seq_i - 1][cat_i] += (feature_potens[seq_i - 1, cat_j] \n",
    "                                              * trans_potens[cat_i, cat_j]\n",
    "                                              * msg[seq_i + 1, seq_i][cat_j])\n",
    "\n",
    "    return msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_messages(feat_potens, trans_potens):\n",
    "    return (calc_messages(feat_potens, trans_potens, forward=True), \n",
    "            calc_messages(feat_potens, trans_potens, forward=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1 - 2</th>\n",
       "      <th>2 - 1</th>\n",
       "      <th>2 - 3</th>\n",
       "      <th>3 - 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>18.589345</td>\n",
       "      <td>49.592435</td>\n",
       "      <td>25.651079</td>\n",
       "      <td>41.809822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t</th>\n",
       "      <td>17.815295</td>\n",
       "      <td>49.133020</td>\n",
       "      <td>25.236859</td>\n",
       "      <td>42.284232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>18.749373</td>\n",
       "      <td>49.567530</td>\n",
       "      <td>25.598383</td>\n",
       "      <td>41.773180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>18.522734</td>\n",
       "      <td>49.522377</td>\n",
       "      <td>25.577943</td>\n",
       "      <td>42.223158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n</th>\n",
       "      <td>18.180753</td>\n",
       "      <td>49.208489</td>\n",
       "      <td>25.271637</td>\n",
       "      <td>42.119828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o</th>\n",
       "      <td>18.677310</td>\n",
       "      <td>49.561131</td>\n",
       "      <td>25.601245</td>\n",
       "      <td>41.835916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s</th>\n",
       "      <td>18.091288</td>\n",
       "      <td>49.016488</td>\n",
       "      <td>25.071460</td>\n",
       "      <td>41.754973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h</th>\n",
       "      <td>18.834070</td>\n",
       "      <td>49.400556</td>\n",
       "      <td>25.388027</td>\n",
       "      <td>42.050850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>18.363419</td>\n",
       "      <td>49.357328</td>\n",
       "      <td>25.414512</td>\n",
       "      <td>42.204460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>18.216396</td>\n",
       "      <td>49.150334</td>\n",
       "      <td>25.202644</td>\n",
       "      <td>42.070277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       1 - 2      2 - 1      2 - 3      3 - 2\n",
       "e  18.589345  49.592435  25.651079  41.809822\n",
       "t  17.815295  49.133020  25.236859  42.284232\n",
       "a  18.749373  49.567530  25.598383  41.773180\n",
       "i  18.522734  49.522377  25.577943  42.223158\n",
       "n  18.180753  49.208489  25.271637  42.119828\n",
       "o  18.677310  49.561131  25.601245  41.835916\n",
       "s  18.091288  49.016488  25.071460  41.754973\n",
       "h  18.834070  49.400556  25.388027  42.050850\n",
       "r  18.363419  49.357328  25.414512  42.204460\n",
       "d  18.216396  49.150334  25.202644  42.070277"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "potens = get_potens(test_case=1)\n",
    "msg_f, msg_b = get_messages(*potens)\n",
    "\n",
    "df = pd.DataFrame(np.log([msg_f[1, 2], msg_b[2, 1], msg_f[2, 3], msg_b[3, 2]]), columns=LABELS)\n",
    "df.index = ['1 - 2', '2 - 1', '2 - 3', '3 - 2']\n",
    "\n",
    "df.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Marginal Probabilties\n",
    "\n",
    "For the first test word only, use the computed messages to compute marginal probability distributions. Report single variable marginals over each position in the word as a table. Represent pairwise marginals over each adjacent node pairs as three tables, and report only the 3 × 3 block of entries between the labels “t,a,h” in each table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>e</th>\n",
       "      <td>7.222682e-12</td>\n",
       "      <td>1.265837e-05</td>\n",
       "      <td>1.132138e-12</td>\n",
       "      <td>8.868280e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t</th>\n",
       "      <td>9.995246e-01</td>\n",
       "      <td>1.724732e-01</td>\n",
       "      <td>2.294512e-08</td>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>2.626167e-11</td>\n",
       "      <td>2.731367e-03</td>\n",
       "      <td>9.994589e-01</td>\n",
       "      <td>2.135660e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>4.727213e-04</td>\n",
       "      <td>1.752834e-04</td>\n",
       "      <td>1.611855e-13</td>\n",
       "      <td>7.405429e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n</th>\n",
       "      <td>7.155546e-11</td>\n",
       "      <td>2.007356e-04</td>\n",
       "      <td>3.697567e-06</td>\n",
       "      <td>3.290041e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o</th>\n",
       "      <td>2.113848e-09</td>\n",
       "      <td>1.400475e-04</td>\n",
       "      <td>1.761094e-08</td>\n",
       "      <td>1.441003e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s</th>\n",
       "      <td>3.295990e-09</td>\n",
       "      <td>1.064607e-07</td>\n",
       "      <td>5.172143e-18</td>\n",
       "      <td>5.371092e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h</th>\n",
       "      <td>4.349270e-11</td>\n",
       "      <td>2.673529e-02</td>\n",
       "      <td>2.835253e-04</td>\n",
       "      <td>1.317807e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <td>2.628090e-06</td>\n",
       "      <td>7.965951e-01</td>\n",
       "      <td>2.537649e-04</td>\n",
       "      <td>6.393979e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>1.069370e-11</td>\n",
       "      <td>9.362852e-04</td>\n",
       "      <td>9.463773e-08</td>\n",
       "      <td>6.373628e-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0             1             2             3\n",
       "e  7.222682e-12  1.265837e-05  1.132138e-12  8.868280e-09\n",
       "t  9.995246e-01  1.724732e-01  2.294512e-08  9.999999e-01\n",
       "a  2.626167e-11  2.731367e-03  9.994589e-01  2.135660e-17\n",
       "i  4.727213e-04  1.752834e-04  1.611855e-13  7.405429e-09\n",
       "n  7.155546e-11  2.007356e-04  3.697567e-06  3.290041e-16\n",
       "o  2.113848e-09  1.400475e-04  1.761094e-08  1.441003e-16\n",
       "s  3.295990e-09  1.064607e-07  5.172143e-18  5.371092e-14\n",
       "h  4.349270e-11  2.673529e-02  2.835253e-04  1.317807e-14\n",
       "r  2.628090e-06  7.965951e-01  2.537649e-04  6.393979e-08\n",
       "d  1.069370e-11  9.362852e-04  9.463773e-08  6.373628e-10"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def calc_marginal_single(feature_potens, trans_potens, msg_f, msg_b):    \n",
    "    seq_len, cat_len = feature_potens.shape\n",
    "    \n",
    "    marginals = []\n",
    "    for seq_i in range(1, seq_len + 1):\n",
    "        p_i = normalize(feature_potens[seq_i - 1,:] * msg_f[seq_i - 1,seq_i] * msg_b[seq_i + 1, seq_i])\n",
    "        marginals.append(np.expand_dims(p_i, axis=0))\n",
    "    \n",
    "    marginals = np.concatenate(marginals)\n",
    "\n",
    "    return marginals\n",
    "\n",
    "potens = get_potens(test_case=1)\n",
    "\n",
    "messages = get_messages(*potens)\n",
    "marginals = calc_marginal_single(*potens, *messages)\n",
    "\n",
    "pd.DataFrame(marginals, columns=LABELS).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Marginal Pair probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>h</th>\n",
       "      <th>a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>t</th>\n",
       "      <td>1.723604e-01</td>\n",
       "      <td>2.672975e-02</td>\n",
       "      <td>2.730539e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h</th>\n",
       "      <td>1.590427e-11</td>\n",
       "      <td>5.389681e-13</td>\n",
       "      <td>7.200092e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>7.465838e-12</td>\n",
       "      <td>3.308640e-13</td>\n",
       "      <td>2.785953e-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              t             h             a\n",
       "t  1.723604e-01  2.672975e-02  2.730539e-03\n",
       "h  1.590427e-11  5.389681e-13  7.200092e-14\n",
       "a  7.465838e-12  3.308640e-13  2.785953e-14"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>h</th>\n",
       "      <th>a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>t</th>\n",
       "      <td>2.231417e-09</td>\n",
       "      <td>0.000066</td>\n",
       "      <td>0.172371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h</th>\n",
       "      <td>1.210440e-09</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.026720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>1.499698e-10</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.002729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              t         h         a\n",
       "t  2.231417e-09  0.000066  0.172371\n",
       "h  1.210440e-09  0.000008  0.026720\n",
       "a  1.499698e-10  0.000001  0.002729"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>t</th>\n",
       "      <th>h</th>\n",
       "      <th>a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>t</th>\n",
       "      <td>2.294512e-08</td>\n",
       "      <td>1.058097e-21</td>\n",
       "      <td>2.079552e-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h</th>\n",
       "      <td>2.835253e-04</td>\n",
       "      <td>2.857058e-18</td>\n",
       "      <td>7.343193e-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>9.994588e-01</td>\n",
       "      <td>1.317085e-14</td>\n",
       "      <td>2.133678e-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              t             h             a\n",
       "t  2.294512e-08  1.058097e-21  2.079552e-24\n",
       "h  2.835253e-04  2.857058e-18  7.343193e-21\n",
       "a  9.994588e-01  1.317085e-14  2.133678e-17"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def calc_marginals_pair(feature_potens, trans_potens, msg_f, msg_b):\n",
    "    seq_len, cat_len = feature_potens.shape\n",
    "\n",
    "    marginals = []\n",
    "    \n",
    "    # There are seq_len - 1 pairs\n",
    "    for pair_i in range(seq_len - 1):\n",
    "        right_scores = (feature_potens[pair_i + 1,:] * msg_b[pair_i + 3,pair_i + 2]).reshape((1, -1))\n",
    "        left_scores = (feature_potens[pair_i,:] * msg_f[pair_i, pair_i + 1]).reshape((-1,1))\n",
    "\n",
    "        scores = left_scores * trans_potens * right_scores\n",
    "        scores = scores / scores.sum()\n",
    "\n",
    "        marginals.append(np.expand_dims(scores, axis=0))\n",
    "\n",
    "    marginals = np.concatenate(marginals)\n",
    "        \n",
    "    return marginals\n",
    "    \n",
    "potens = get_potens(test_case=1) \n",
    "messages = get_messages(*potens)\n",
    "\n",
    "marginals = calc_marginals_pair(*potens, *messages)\n",
    "\n",
    "for marginal in marginals:\n",
    "    df = pd.DataFrame(marginal, columns=LABELS)\n",
    "    df.index = LABELS\n",
    "    display(df.loc[['t','h','a'], ['t', 'h', 'a']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Inference over test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Get predictions for first 3 test words\n",
    "def predict_crf(test_case=1):\n",
    "    feat_potens, trans_potens = get_potens(test_case)\n",
    "    msg_f, msg_b = get_messages(feat_potens, trans_potens)\n",
    "\n",
    "    seq_len, cat_len = feat_potens.shape\n",
    "    \n",
    "    # Shape (seq_len, 10)\n",
    "    single_marginals = calc_marginal_single(feat_potens, trans_potens, msg_f, msg_b)\n",
    "\n",
    "    # Shape (seq_len, 10, 10)\n",
    "    pair_marginals = calc_marginals_pair(feat_potens, trans_potens, msg_f, msg_b)\n",
    "    \n",
    "    # Pad pair_marginals with ones to simplify calculation\n",
    "    pair_marginals = np.vstack((np.ones((1, 10, 10)), pair_marginals))\n",
    "        \n",
    "    prediction = []\n",
    "    cat_label = 0\n",
    "    for seq_i in range(seq_len):\n",
    "        cat_label = np.argmax(pair_marginals[seq_i, cat_label] * single_marginals[seq_i])\n",
    "        prediction.append(label_to_char[cat_label])\n",
    "    \n",
    "    return ''.join(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual:  that Pred:  trat\n",
      "Actual:  hire Pred:  hire\n",
      "Actual:  rises Pred:  riser\n",
      "Actual:  edison Pred:  edison\n",
      "Actual:  shore Pred:  shore\n",
      "Actual:  tenth Pred:  tenth\n",
      "Actual:  not Pred:  hot\n",
      "Actual:  tests Pred:  tests\n",
      "Actual:  trains Pred:  trains\n",
      "Actual:  order Pred:  order\n"
     ]
    }
   ],
   "source": [
    "# Predictions over first 5 test words\n",
    "with open('./data/test_words.txt') as f:\n",
    "    num = 10\n",
    "    for idx, actual in enumerate(f.readlines()):\n",
    "        if idx == num:\n",
    "            break\n",
    "        print('Actual: ', actual.rstrip(), 'Pred: ', predict_crf(test_case=idx+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8991674375578168\n"
     ]
    }
   ],
   "source": [
    "words = None\n",
    "with open('./data/test_words.txt') as f:\n",
    "    words = [line.rsplit('\\n')[0] for line in f.readlines()]\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for i in range(1, 201):\n",
    "    prediction = predict_crf(test_case=i)\n",
    "    for char_p, char_t in zip(list(prediction), list(words[i - 1])):\n",
    "        if char_p == char_t: \n",
    "            correct += 1\n",
    "        total += 1\n",
    "\n",
    "print('Accuracy: ', correct / total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Maximum Likelihood Learning Derivation\n",
    "\n",
    "In this problem, you will derive the maximum likelihood learning algorithm for conditional random field model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Average log likelihood\n",
    "\n",
    "Using a dataset consisting of the first 50 training data cases only, compute the average log likelihood of the true label sequences given the image sequences using the supplied model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_log_partition_v2(feat_potens, msg):\n",
    "    log_partition = feat_potens[0] * msg[2,1]\n",
    "    log_partition = log_partition.sum()\n",
    "    log_partition = np.log(log_partition)\n",
    "    \n",
    "    return log_partition\n",
    "\n",
    "# Read training data\n",
    "def compute_likelihood(num):\n",
    "    # Get features\n",
    "    features = get_features(num + 1, split='train') \n",
    "    \n",
    "    feat_potens = calc_feat_potential(features, feature_params)\n",
    "    trans_potens = calc_tran_potential(transition_params)\n",
    "    \n",
    "    msg_f, msg_b = get_messages(feat_potens, trans_potens)\n",
    "\n",
    "    seq_len, cat_len = feat_potens.shape\n",
    "    \n",
    "    log_partition = calc_log_partition_v2(feat_potens, msg_b)\n",
    "    \n",
    "    labels = train_labels[num]    \n",
    "    feat_potens_val = np.log(feat_potens[range(seq_len),  labels]).sum()\n",
    "    trans_potens_val = transition_params[labels[:-1], labels[1:]].sum()\n",
    "    \n",
    "    likelihood = feat_potens_val + trans_potens_val - log_partition\n",
    "    \n",
    "    return likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.583959036355722"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Averate likelihood\n",
    "num = 50\n",
    "avg_likelihood = np.mean([compute_likelihood(i) for i in range(num)])\n",
    "avg_likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Numerical Optimizaion warm-up\n",
    "\n",
    "In the next assignment, you will im- plement the above learning algorithm using a numerical optimizer to maximize the log likelihood. In this question, you will experiment with optimizing a basic function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      fun: 1.2586977413785688e-16\n",
       " hess_inv: <2x2 LbfgsInvHessProduct with dtype=float64>\n",
       "      jac: array([ 2.71276770e-07, -1.44232692e-07])\n",
       "  message: b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL'\n",
       "     nfev: 32\n",
       "      nit: 26\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([0.99999999, 0.99999998])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def objective(vec):\n",
    "    x, y = vec\n",
    "    return (1 - x) ** 2 + 100*((y - x ** 2) ** 2)\n",
    "\n",
    "def calc_jacardian(vec):\n",
    "    '''Gradient of the objective function'''\n",
    "    x, y = vec\n",
    "\n",
    "    return -np.array([\n",
    "        2 * (1 - x) + 400 * x * (y - x ** 2),\n",
    "        -200*(y - x ** 2)\n",
    "    ])\n",
    "\n",
    "xy = np.array([1, -1])\n",
    "\n",
    "# Calculate gradient numerically\n",
    "# minimize(objective, xy)\n",
    "\n",
    "minimize(objective, xy, jac=calc_jacardian, method='L-BFGS-B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use average log conditional likelihood as the objective function. Implement the objective function, and also its gradient functions (the computation of the partial derivatives of the objective function with respect to each parameter), as derived in Assignment 2. Use your implementation of the sum-product message passing algorithm from Assignment 2 as a subroutine to make your objective and gradient function implementations computationally tractable. Implement the learning algorithm for CRFs by using the numerical optimizer you selected in Assignment 2 to maximize the log conditional likelihood function. Use the first 50, 100, 150, 200, 250, 300, 350 and 400 training data cases to train eight separate CRF models. Answer the following questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes = [50, 100, 150, 200, 250, 300, 350, 400]\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    # Read batch_size training examples\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1\n",
    "\n",
    "Record the total training time in seconds for each of the above training data set sizes. Report your results as a line graph of time in seconds versus training set size. Make sure to label the axes of your plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2\n",
    "\n",
    "Evaluate the prediction error of each model on the complete test set. As in Assignment 2, predict the character with the highest marginal probability for each position of each test word. Report the error rate averaged over all predicted characters in all test words for each model. Summarize your test error results in a line graph showing prediction error versus training set size. Make sure to label the axes of your plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3\n",
    "\n",
    "Evaluate the average conditional log likelihood of the complete test set under each model (for each model, this will be an average of the per-word conditional log likelihoods for each word in the test set). Summarize your results in a line graph showing average conditional log likelihood versus training set size. Make sure to label the axes of your plot."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
